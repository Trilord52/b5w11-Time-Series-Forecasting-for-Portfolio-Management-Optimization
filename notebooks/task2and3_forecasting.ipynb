{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks 2 & 3: Time Series Forecasting and Future Trend Analysis\n",
    "\n",
    "**Time Series Forecasting for Portfolio Management Optimization**  \n",
    "**Guide Me in Finance (GMF) Investments**\n",
    "\n",
    "This notebook implements:\n",
    "1. ARIMA/SARIMA forecasting models\n",
    "2. Model comparison and evaluation\n",
    "3. 12-month future trend forecasts\n",
    "4. Risk and volatility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import FinancialDataLoader\n",
    "from preprocessing import FinancialDataPreprocessor\n",
    "from forecasting_models import TimeSeriesForecaster\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.makedirs('../results/forecasting', exist_ok=True)\n",
    "\n",
    "start_date = \"2015-07-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "target_asset = \"TSLA\"\n",
    "forecast_horizon_days = 252  # 12 months\n",
    "\n",
    "print(f\"Target Asset: {target_asset}\")\n",
    "print(f\"Forecast Horizon: 12 months ({forecast_horizon_days} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Prepare Data\n",
    "print(\"Loading TSLA data...\")\n",
    "loader = FinancialDataLoader(start_date=start_date, end_date=end_date)\n",
    "tsla_data = loader.fetch_asset_data(target_asset)\n",
    "\n",
    "if tsla_data is not None:\n",
    "    print(f\"‚úì {len(tsla_data)} records loaded\")\n",
    "    print(f\"Current Price: ${tsla_data['Close'].iloc[-1]:.2f}\")\n",
    "    \n",
    "    # Preprocess\n",
    "    preprocessor = FinancialDataPreprocessor()\n",
    "    processed_data = preprocessor.preprocess_asset_data({target_asset: tsla_data})\n",
    "    tsla_processed = processed_data[target_asset]\n",
    "    print(f\"‚úì Data preprocessed: {len(tsla_processed)} records\")\n",
    "else:\n",
    "    print(\"Failed to load data\")\n",
    "    # Handle missing values (NaNs) in the processed data\n",
    "if tsla_processed.isnull().values.any():\n",
    "    print(\"Warning: Missing values detected. Filling with forward fill and back fill.\")\n",
    "    tsla_processed = tsla_processed.fillna(method='ffill').fillna(method='bfill')\n",
    "else:\n",
    "    print(\"‚úì No missing values detected in processed data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    " Visualize missing values, outliers, and basic statistics for TSLA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(10, 1))\n",
    "sns.heatmap(tsla_processed.isnull().T, cbar=False)\n",
    "plt.title(\"Missing Values in TSLA Processed Data\")\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "display(tsla_processed.describe())\n",
    "\n",
    "# Outlier detection (boxplot)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(x=tsla_processed['Close'])\n",
    "plt.title(\"TSLA Close Price Outlier Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Technical Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    df = df.copy()\n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + df['Close'].pct_change().add(1).rolling(window=14).apply(lambda x: (x[x > 0].sum() / abs(x[x < 0].sum())) if abs(x[x < 0].sum()) > 0 else 0)))\n",
    "    return df\n",
    "\n",
    "tsla_processed = add_technical_indicators(tsla_processed)\n",
    "display(tsla_processed.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare for Modeling\n",
    "forecaster = TimeSeriesForecaster()\n",
    "\n",
    "# Split data chronologically\n",
    "train_data, test_data, train_dates, test_dates = forecaster.prepare_data_for_modeling(\n",
    "    tsla_processed, target_column='Close', test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(train_data)} samples ({train_dates[0].strftime('%Y-%m-%d')} to {train_dates[-1].strftime('%Y-%m-%d')})\")\n",
    "print(f\"Testing: {len(test_data)} samples ({test_dates[0].strftime('%Y-%m-%d')} to {test_dates[-1].strftime('%Y-%m-%d')})\")\n",
    "\n",
    "# Visualize split\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_data.values, label='Test Data', color='red')\n",
    "plt.title(f'{target_asset} Price Data - Train/Test Split')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ARIMA Model\n",
    "print(\"Training ARIMA Model...\")\n",
    "model_results = {}\n",
    "\n",
    "try:\n",
    "    # Check stationarity\n",
    "    stationarity = forecaster.check_stationarity(train_data)\n",
    "    print(f\"Stationarity: {stationarity['conclusion']} (p-value: {stationarity['p_value']:.6f})\")\n",
    "    \n",
    "    # Fit ARIMA\n",
    "    arima_model = forecaster.fit_arima_model(train_data)\n",
    "    arima_forecasts = forecaster.generate_forecasts(\n",
    "        'ARIMA', test_data, forecast_horizon_days, confidence_level=0.95\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    if len(arima_forecasts['out_sample_predictions']) > 0:\n",
    "        arima_performance = forecaster.evaluate_model_performance(\n",
    "            'ARIMA', test_data, arima_forecasts['out_sample_predictions']\n",
    "        )\n",
    "        \n",
    "        model_results['ARIMA'] = {\n",
    "            'model': arima_model,\n",
    "            'forecasts': arima_forecasts,\n",
    "            'performance': arima_performance\n",
    "        }\n",
    "        \n",
    "        print(\"‚úì ARIMA model successful\")\n",
    "        print(f\"  RMSE: {arima_performance['RMSE']:.4f}\")\n",
    "        print(f\"  MAPE: {arima_performance['MAPE']:.2f}%\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚úó ARIMA failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: SARIMA Model (Simplified)\n",
    "print(\"Training SARIMA Model (simplified parameters)...\")\n",
    "\n",
    "try:\n",
    "    sarima_model = forecaster.fit_sarima_model(train_data)\n",
    "    sarima_forecasts = forecaster.generate_forecasts(\n",
    "        'SARIMA', test_data, forecast_horizon_days, confidence_level=0.95\n",
    "    )\n",
    "    \n",
    "    if len(sarima_forecasts['out_sample_predictions']) > 0:\n",
    "        sarima_performance = forecaster.evaluate_model_performance(\n",
    "            'SARIMA', test_data, sarima_forecasts['out_sample_predictions']\n",
    "        )\n",
    "        \n",
    "        model_results['SARIMA'] = {\n",
    "            'model': sarima_model,\n",
    "            'forecasts': sarima_forecasts,\n",
    "            'performance': sarima_performance\n",
    "        }\n",
    "        \n",
    "        print(\"‚úì SARIMA model successful\")\n",
    "        print(f\"  RMSE: {sarima_performance['RMSE']:.4f}\")\n",
    "        print(f\"  MAPE: {sarima_performance['MAPE']:.2f}%\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚úó SARIMA failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "best_aic = float('inf')\n",
    "best_order = None\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = sm.tsa.ARIMA(train_data, order=order)\n",
    "        results = model.fit()\n",
    "        if results.aic < best_aic:\n",
    "            best_aic = results.aic\n",
    "            best_order = order\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Best ARIMA order: {best_order} (AIC={best_aic:.2f})\")\n",
    "arima_model = sm.tsa.ARIMA(train_data, order=best_order).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation for ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "history = list(train_data.values)\n",
    "predictions = []\n",
    "for t in range(len(test_data)):\n",
    "    model = sm.tsa.ARIMA(history, order=best_order)\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    history.append(test_data.values[t])\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_data, predictions))\n",
    "print(f\"Walk-forward RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b: LSTM Model (Deep Learning)\n",
    "We implement an LSTM neural network to capture non-linear temporal dependencies in TSLA price data. The model is trained on scaled, windowed sequences and evaluated on out-of-sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: LSTM Model (Deep Learning)\n",
    "print(\"Training LSTM Model...\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Prepare data for LSTM (scale and create sequences)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "scaled_test = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, seq_length=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 30\n",
    "X_train, y_train = create_sequences(scaled_train, seq_length)\n",
    "# For test, concatenate last part of train with test for continuity\n",
    "X_test, y_test = create_sequences(np.concatenate([scaled_train[-seq_length:], scaled_test]), seq_length)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train LSTM\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, \n",
    "               validation_split=0.1, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "# Predict on test set\n",
    "lstm_preds_scaled = lstm_model.predict(X_test)\n",
    "lstm_preds = scaler.inverse_transform(lstm_preds_scaled)\n",
    "\n",
    "# Align test set for comparison\n",
    "lstm_test_actual = test_data.values[seq_length:]\n",
    "\n",
    "# Evaluate LSTM\n",
    "rmse = np.sqrt(mean_squared_error(lstm_test_actual, lstm_preds))\n",
    "mae = mean_absolute_error(lstm_test_actual, lstm_preds)\n",
    "mape = np.mean(np.abs((lstm_test_actual - lstm_preds.flatten()) / lstm_test_actual)) * 100\n",
    "direction_acc = np.mean(\n",
    "    np.sign(np.diff(lstm_test_actual)) == np.sign(np.diff(lstm_preds.flatten()))\n",
    ")\n",
    "\n",
    "lstm_performance = {\n",
    "    'RMSE': rmse,\n",
    "    'MAE': mae,\n",
    "    'MAPE': mape,\n",
    "    'Direction_Accuracy': direction_acc\n",
    "}\n",
    "\n",
    "# Generate 12-month (252 trading days) future forecast using LSTM\n",
    "def forecast_lstm_future(model, last_sequence, n_steps, scaler):\n",
    "    preds = []\n",
    "    current_seq = last_sequence.copy()\n",
    "    for _ in range(n_steps):\n",
    "        pred = model.predict(current_seq.reshape(1, -1, 1), verbose=0)\n",
    "        preds.append(pred[0, 0])\n",
    "        current_seq = np.roll(current_seq, -1)\n",
    "        current_seq[-1] = pred\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    return scaler.inverse_transform(preds).flatten()\n",
    "\n",
    "# Prepare last sequence from all data for future forecasting\n",
    "full_scaled = scaler.transform(tsla_processed['Close'].values.reshape(-1, 1))\n",
    "last_seq = full_scaled[-seq_length:]\n",
    "future_lstm_forecast = forecast_lstm_future(lstm_model, last_seq, forecast_horizon_days, scaler)\n",
    "\n",
    "# Create future forecast index\n",
    "future_dates = pd.date_range(tsla_processed.index[-1] + pd.Timedelta(days=1), periods=forecast_horizon_days, freq='B')\n",
    "future_lstm_forecast_series = pd.Series(future_lstm_forecast, index=future_dates, name='LSTM_Forecast')\n",
    "\n",
    "model_results['LSTM'] = {\n",
    "    'model': lstm_model,\n",
    "    'forecasts': {\n",
    "        'out_sample_predictions': lstm_preds.flatten(),\n",
    "        'future_forecast': future_lstm_forecast_series\n",
    "    },\n",
    "    'performance': lstm_performance\n",
    "}\n",
    "\n",
    "print(\"‚úì LSTM model successful\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved LSTM Model with Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_lstm(units=50, dropout=0.2):\n",
    "    model = Sequential([\n",
    "        LSTM(units, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "        Dropout(dropout),\n",
    "        LSTM(units),\n",
    "        Dropout(dropout),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "lstm_reg = KerasRegressor(build_fn=build_lstm, epochs=30, batch_size=32, verbose=0)\n",
    "param_grid = {'units': [32, 50], 'dropout': [0.2, 0.3]}\n",
    "grid = GridSearchCV(lstm_reg, param_grid, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best LSTM params:\", grid.best_params_)\n",
    "\n",
    "# Use best params for final model\n",
    "best_lstm = build_lstm(**grid.best_params_)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "best_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stop], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Comparison\n",
    "if model_results:\n",
    "    comparison_data = []\n",
    "    for model_name, results in model_results.items():\n",
    "        perf = results['performance']\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'RMSE': perf['RMSE'],\n",
    "            'MAPE': perf['MAPE'],\n",
    "            'Direction_Accuracy': perf['Direction_Accuracy']\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data).round(4)\n",
    "    comparison_df = comparison_df.sort_values('RMSE')\n",
    "    \n",
    "    print(\"\\nModel Performance Comparison:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    best_model = comparison_df.iloc[0]['Model']\n",
    "    print(f\"\\nüèÜ Best Model: {best_model}\")\n",
    "else:\n",
    "    print(\"No successful models\")\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Future Trend Analysis\n",
    "if best_model and best_model in model_results:\n",
    "    forecasts = model_results[best_model]['forecasts']\n",
    "    future_forecast = forecasts['future_forecast']\n",
    "    \n",
    "    current_price = tsla_processed['Close'].iloc[-1]\n",
    "    forecast_end = future_forecast.iloc[-1]\n",
    "    total_return = ((forecast_end - current_price) / current_price) * 100\n",
    "    \n",
    "    print(f\"\\nüìà 12-Month Forecast Summary ({best_model}):\")\n",
    "    print(f\"  Current Price: ${current_price:.2f}\")\n",
    "    print(f\"  Forecasted End Price: ${forecast_end:.2f}\")\n",
    "    print(f\"  Expected Return: {total_return:.2f}%\")\n",
    "    print(f\"  Trend: {'Bullish' if total_return > 0 else 'Bearish'}\")\n",
    "    print(f\"  Max Forecast: ${future_forecast.max():.2f}\")\n",
    "    print(f\"  Min Forecast: ${future_forecast.min():.2f}\")\n",
    "    \n",
    "    # Risk Analysis\n",
    "    returns = future_forecast.pct_change().dropna()\n",
    "    var_95 = np.percentile(returns, 5) * 100\n",
    "    max_dd = ((1 + returns).cumprod() / (1 + returns).cumprod().expanding().max() - 1).min() * 100\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Risk Metrics:\")\n",
    "    print(f\"  VaR (95%): {var_95:.2f}%\")\n",
    "    print(f\"  Max Drawdown: {max_dd:.2f}%\")\n",
    "    print(f\"  Volatility: {returns.std() * np.sqrt(252) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualization\n",
    "if best_model and best_model in model_results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Forecast\n",
    "    ax1 = axes[0, 0]\n",
    "    recent = tsla_processed['Close'].iloc[-252:]\n",
    "    ax1.plot(recent.index, recent.values, label='Historical', color='black')\n",
    "    ax1.plot(future_forecast.index, future_forecast.values, \n",
    "             label=f'{best_model} Forecast', color='red', linewidth=2)\n",
    "    \n",
    "    if 'confidence_intervals' in forecasts:\n",
    "        ci = forecasts['confidence_intervals']\n",
    "        ax1.fill_between(future_forecast.index, ci.iloc[:, 0], ci.iloc[:, 1],\n",
    "                        alpha=0.3, color='red', label='95% CI')\n",
    "    \n",
    "    ax1.set_title('12-Month Price Forecast')\n",
    "    ax1.set_ylabel('Price ($)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Returns Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(returns, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax2.axvline(returns.mean(), color='red', linestyle='--', label=f'Mean: {returns.mean():.4f}')\n",
    "    ax2.set_title('Forecasted Returns Distribution')\n",
    "    ax2.set_xlabel('Daily Returns')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Cumulative Returns\n",
    "    ax3 = axes[1, 0]\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    ax3.plot(future_forecast.index[1:], cum_returns, color='green', linewidth=2)\n",
    "    ax3.set_title('Forecasted Cumulative Returns')\n",
    "    ax3.set_ylabel('Cumulative Return')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Rolling Volatility\n",
    "    ax4 = axes[1, 1]\n",
    "    rolling_vol = returns.rolling(30).std() * np.sqrt(252) * 100\n",
    "    ax4.plot(future_forecast.index[1:], rolling_vol, color='orange', linewidth=2)\n",
    "    ax4.set_title('30-Day Rolling Volatility')\n",
    "    ax4.set_ylabel('Volatility (%)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all model future forecasts for comparison\n",
    "plt.figure(figsize=(15, 6))\n",
    "recent = tsla_processed['Close'].iloc[-252:]\n",
    "plt.plot(recent.index, recent.values, label='Historical', color='black')\n",
    "for model_name, results in model_results.items():\n",
    "    if 'future_forecast' in results['forecasts']:\n",
    "        plt.plot(results['forecasts']['future_forecast'].index, \n",
    "                 results['forecasts']['future_forecast'].values, \n",
    "                 label=f\"{model_name} Forecast\")\n",
    "plt.title('12-Month Price Forecasts: All Models')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save Results\n",
    "if best_model and best_model in model_results:\n",
    "    # Save forecast data\n",
    "    future_forecast.to_csv('../results/forecasting/future_forecasts.csv')\n",
    "    comparison_df.to_csv('../results/forecasting/model_comparison.csv', index=False)\n",
    "    \n",
    "    print(\"\\n‚úì Results saved to:\")\n",
    "    print(\"  - ../results/forecasting/future_forecasts.csv\")\n",
    "    print(\"  - ../results/forecasting/model_comparison.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TASKS 2 & 3 COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"‚úì Best Model: {best_model}\")\n",
    "    print(f\"‚úì 12-month forecast generated\")\n",
    "    print(f\"‚úì Risk analysis completed\")\n",
    "    print(f\"‚úì Visualizations created\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Analysis incomplete - no successful models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Selection and Results Summary\n",
    "\n",
    "In this notebook, we implemented and compared ARIMA, SARIMA, and LSTM models for time series forecasting of TSLA stock prices. Each model was evaluated using RMSE, MAE, MAPE, and Direction Accuracy. We generated 12-month forecasts and analyzed risk metrics such as Value at Risk (VaR), maximum drawdown, and volatility.\n",
    "\n",
    "**Key Findings:**\n",
    "- The best-performing model was selected based on the lowest RMSE on the test set.\n",
    "- All models captured the general trend, but the LSTM model was able to learn non-linear patterns and provided competitive accuracy.\n",
    "- Risk analysis on the forecasted period highlighted potential drawdowns and volatility, which are critical for portfolio management.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Conclusion and Recommendations\n",
    "\n",
    "- **Model Choice:** The selected best model (see above) is recommended for short-term TSLA price forecasting, but all models should be monitored for performance drift.\n",
    "- **Forecast Reliability:** Confidence intervals (where available) provide a measure of uncertainty. Forecasts should be interpreted as probabilistic, not deterministic.\n",
    "- **Limitations:** Forecasts are based solely on historical price data and do not account for external factors (e.g., macroeconomic events, news).\n",
    "- **Next Steps:** Integrate forecasts with portfolio optimization and backtesting for robust investment decision-making. Regularly retrain models with new data for continued accuracy.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
